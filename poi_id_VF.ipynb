{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to Identify Fraud in the Enron Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alexandra AMIENS\n",
    "LÃ©o ITURRIOZ\n",
    "Erwan HENRY DE VILLENEUVE\n",
    "Julieva COHEN-SORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the packages we need to build our predictive model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "#from poi_data import*\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from plotly import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Select Feature we'll use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete an exploratory analysis and choose which features is the best (part 3), we will use all the features in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 'poi'\n",
    "\n",
    "email_features_list = [\n",
    "    'from_messages',\n",
    "    'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi',\n",
    "    'shared_receipt_with_poi',\n",
    "    'to_messages',\n",
    "    ]\n",
    "    \n",
    "financial_features_list = [\n",
    "    'bonus',\n",
    "    'deferral_payments',\n",
    "    'deferred_income',\n",
    "    'director_fees',\n",
    "    'exercised_stock_options',\n",
    "    'expenses',\n",
    "    'loan_advances',\n",
    "    'long_term_incentive',\n",
    "    'other',\n",
    "    'restricted_stock',\n",
    "    'restricted_stock_deferred',\n",
    "    'salary',\n",
    "    'total_payments',\n",
    "    'total_stock_value',\n",
    "]\n",
    "\n",
    "features_list = [target_label] + financial_features_list + email_features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dictionary containing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(data_dict):\n",
    "    \"\"\" generates a csv file from a data set\"\"\"\n",
    "    fieldnames = ['name'] + data_dict.itervalues().next().keys()\n",
    "    with open('data.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in data_dict:\n",
    "            person = data_dict[record]\n",
    "            person['name'] = record\n",
    "            assert set(person.keys()) == set(fieldnames)\n",
    "            writer.writerow(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploratory Data Analysis #\n",
      "Total number of data points: 146\n",
      "Number of Persons of Interest: 18\n",
      "Number of people without Person of Interest label: 128\n"
     ]
    }
   ],
   "source": [
    "print('# Exploratory Data Analysis #')\n",
    "data_dict.keys()\n",
    "print('Total number of data points: %d' % len(data_dict.keys()))\n",
    "num_poi = 0\n",
    "for name in data_dict.keys():\n",
    "    if data_dict[name]['poi'] == True:\n",
    "        num_poi += 1\n",
    "print('Number of Persons of Interest: %d' % num_poi)\n",
    "print('Number of people without Person of Interest label: %d' % (len(data_dict.keys()) - num_poi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each person has 21 features available\n"
     ]
    }
   ],
   "source": [
    "all_features = data_dict['ALLEN PHILLIP K'].keys()\n",
    "print('Each person has %d features available' %  len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate dataset for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = {}\n",
    "for feature in all_features:\n",
    "    missing_values[feature] = 0\n",
    "for person in data_dict.keys():\n",
    "    records = 0\n",
    "    for feature in all_features:\n",
    "        if data_dict[person][feature] == 'NaN':\n",
    "            missing_values[feature] += 1\n",
    "        else:\n",
    "            records += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results of completeness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values for Each Feature:\n",
      "loan_advances 142\n",
      "director_fees 129\n",
      "restricted_stock_deferred 128\n",
      "deferral_payments 107\n",
      "deferred_income 97\n",
      "long_term_incentive 80\n",
      "bonus 64\n",
      "to_messages 60\n",
      "from_poi_to_this_person 60\n",
      "from_messages 60\n",
      "from_this_person_to_poi 60\n",
      "shared_receipt_with_poi 60\n",
      "other 53\n",
      "salary 51\n",
      "expenses 51\n",
      "exercised_stock_options 44\n",
      "restricted_stock 36\n",
      "email_address 35\n",
      "total_payments 21\n",
      "total_stock_value 20\n",
      "poi 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of Missing Values for Each Feature:')\n",
    "#for feature in all_features:\n",
    "    #print(\"%s: %d\" % (feature, missing_values[feature]))\n",
    "\n",
    "for id in sorted(missing_values, key = missing_values.get, reverse = True):\n",
    "        print(id, missing_values[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We convert the dictionary values into a dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_data = pd.DataFrame.from_dict(data_dict, orient = 'index') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data exploration and deal with/remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METTS MARK</th>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <th>MORDAUNT KRISTINA M</th>\n",
       "      <th>MEYER ROCKFORD G</th>\n",
       "      <th>MCMAHON JEFFREY</th>\n",
       "      <th>HAEDICKE MARK E</th>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <th>...</th>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <th>IZZO LAWRENCE L</th>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <th>MARTIN AMANDA K</th>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>365788</td>\n",
       "      <td>267102</td>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293</td>\n",
       "      <td>267093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370448</td>\n",
       "      <td>374125</td>\n",
       "      <td>197091</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85274</td>\n",
       "      <td>247338</td>\n",
       "      <td>349487</td>\n",
       "      <td>330546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415189</td>\n",
       "      <td>265214</td>\n",
       "      <td>278601</td>\n",
       "      <td>274975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>764</td>\n",
       "      <td>1045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>2355</td>\n",
       "      <td>4009</td>\n",
       "      <td>1238</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>460</td>\n",
       "      <td>1522</td>\n",
       "      <td>3523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1892</td>\n",
       "      <td>533</td>\n",
       "      <td>865</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1848227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2157527</td>\n",
       "      <td>1130036</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85430</td>\n",
       "      <td>649584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>1061827</td>\n",
       "      <td>5634343</td>\n",
       "      <td>211725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288682</td>\n",
       "      <td>628522</td>\n",
       "      <td>1848227</td>\n",
       "      <td>4099771</td>\n",
       "      <td>3859065</td>\n",
       "      <td>1737629</td>\n",
       "      <td>...</td>\n",
       "      <td>3750</td>\n",
       "      <td>1979596</td>\n",
       "      <td>399393</td>\n",
       "      <td>8407016</td>\n",
       "      <td>2355702</td>\n",
       "      <td>119292</td>\n",
       "      <td>1868758</td>\n",
       "      <td>1092663</td>\n",
       "      <td>875760</td>\n",
       "      <td>1272284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>600000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500000</td>\n",
       "      <td>325000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600000</td>\n",
       "      <td>1150000</td>\n",
       "      <td>400000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "      <td>600000</td>\n",
       "      <td>800000</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>kristina.mordaunt@enron.com</td>\n",
       "      <td>rockford.meyer@enron.com</td>\n",
       "      <td>jeffrey.mcmahon@enron.com</td>\n",
       "      <td>mark.haedicke@enron.com</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>larry.izzo@enron.com</td>\n",
       "      <td>elizabeth.tilney@enron.com</td>\n",
       "      <td>a..martin@enron.com</td>\n",
       "      <td>rick.buy@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>richard.causey@enron.com</td>\n",
       "      <td>mitchell.taylor@enron.com</td>\n",
       "      <td>jeff.donahue@enron.com</td>\n",
       "      <td>ben.glisan@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-329825</td>\n",
       "      <td>-409554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>-400729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-934484</td>\n",
       "      <td>-33333</td>\n",
       "      <td>...</td>\n",
       "      <td>-121284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-575000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-694862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-235000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>585062</td>\n",
       "      <td>10623258</td>\n",
       "      <td>6678735</td>\n",
       "      <td>1038185</td>\n",
       "      <td>6391065</td>\n",
       "      <td>208510</td>\n",
       "      <td>955873</td>\n",
       "      <td>1662855</td>\n",
       "      <td>803094</td>\n",
       "      <td>880290</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5819980</td>\n",
       "      <td>1168042</td>\n",
       "      <td>2070306</td>\n",
       "      <td>3444470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2502063</td>\n",
       "      <td>3745048</td>\n",
       "      <td>1080988</td>\n",
       "      <td>778546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>94299</td>\n",
       "      <td>11200</td>\n",
       "      <td>78552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34039</td>\n",
       "      <td>35018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137108</td>\n",
       "      <td>76169</td>\n",
       "      <td>43057</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96268</td>\n",
       "      <td>125978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>180</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>4890344</td>\n",
       "      <td>651850</td>\n",
       "      <td>5538001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>493489</td>\n",
       "      <td>1104054</td>\n",
       "      <td>608750</td>\n",
       "      <td>880290</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2165172</td>\n",
       "      <td>591250</td>\n",
       "      <td>2070306</td>\n",
       "      <td>2542813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3181250</td>\n",
       "      <td>765920</td>\n",
       "      <td>384728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>1941</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>230</td>\n",
       "      <td>1053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>1740</td>\n",
       "      <td>2660303</td>\n",
       "      <td>12961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11350</td>\n",
       "      <td>1411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>297353</td>\n",
       "      <td>52382</td>\n",
       "      <td>778</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553729</td>\n",
       "      <td>152055</td>\n",
       "      <td>2818454</td>\n",
       "      <td>400572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>200308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1617011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>694862</td>\n",
       "      <td>983346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312500</td>\n",
       "      <td>275000</td>\n",
       "      <td>5145434</td>\n",
       "      <td>769862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>1035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>2228</td>\n",
       "      <td>1847</td>\n",
       "      <td>742</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437</td>\n",
       "      <td>379</td>\n",
       "      <td>477</td>\n",
       "      <td>2333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1585</td>\n",
       "      <td>300</td>\n",
       "      <td>772</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>585062</td>\n",
       "      <td>3942714</td>\n",
       "      <td>1788391</td>\n",
       "      <td>386335</td>\n",
       "      <td>853064</td>\n",
       "      <td>208510</td>\n",
       "      <td>462384</td>\n",
       "      <td>558801</td>\n",
       "      <td>524169</td>\n",
       "      <td>409554</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3654808</td>\n",
       "      <td>576792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>901657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2502063</td>\n",
       "      <td>563798</td>\n",
       "      <td>315068</td>\n",
       "      <td>393818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>125034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     METTS MARK BAXTER JOHN C  \\\n",
       "salary                                   365788        267102   \n",
       "to_messages                                 807           NaN   \n",
       "deferral_payments                           NaN       1295738   \n",
       "total_payments                          1061827       5634343   \n",
       "loan_advances                               NaN           NaN   \n",
       "bonus                                    600000       1200000   \n",
       "email_address              mark.metts@enron.com           NaN   \n",
       "restricted_stock_deferred                   NaN           NaN   \n",
       "deferred_income                             NaN      -1386055   \n",
       "total_stock_value                        585062      10623258   \n",
       "expenses                                  94299         11200   \n",
       "from_poi_to_this_person                      38           NaN   \n",
       "exercised_stock_options                     NaN       6680544   \n",
       "from_messages                                29           NaN   \n",
       "other                                      1740       2660303   \n",
       "from_this_person_to_poi                       1           NaN   \n",
       "poi                                       False         False   \n",
       "long_term_incentive                         NaN       1586055   \n",
       "shared_receipt_with_poi                     702           NaN   \n",
       "restricted_stock                         585062       3942714   \n",
       "director_fees                               NaN           NaN   \n",
       "\n",
       "                                     ELLIOTT STEVEN       CORDES WILLIAM R  \\\n",
       "salary                                       170941                    NaN   \n",
       "to_messages                                     NaN                    764   \n",
       "deferral_payments                               NaN                    NaN   \n",
       "total_payments                               211725                    NaN   \n",
       "loan_advances                                   NaN                    NaN   \n",
       "bonus                                        350000                    NaN   \n",
       "email_address              steven.elliott@enron.com  bill.cordes@enron.com   \n",
       "restricted_stock_deferred                       NaN                    NaN   \n",
       "deferred_income                             -400729                    NaN   \n",
       "total_stock_value                           6678735                1038185   \n",
       "expenses                                      78552                    NaN   \n",
       "from_poi_to_this_person                         NaN                     10   \n",
       "exercised_stock_options                     4890344                 651850   \n",
       "from_messages                                   NaN                     12   \n",
       "other                                         12961                    NaN   \n",
       "from_this_person_to_poi                         NaN                      0   \n",
       "poi                                           False                  False   \n",
       "long_term_incentive                             NaN                    NaN   \n",
       "shared_receipt_with_poi                         NaN                     58   \n",
       "restricted_stock                            1788391                 386335   \n",
       "director_fees                                   NaN                    NaN   \n",
       "\n",
       "                                   HANNON KEVIN P  \\\n",
       "salary                                     243293   \n",
       "to_messages                                  1045   \n",
       "deferral_payments                             NaN   \n",
       "total_payments                             288682   \n",
       "loan_advances                                 NaN   \n",
       "bonus                                     1500000   \n",
       "email_address              kevin.hannon@enron.com   \n",
       "restricted_stock_deferred                     NaN   \n",
       "deferred_income                          -3117011   \n",
       "total_stock_value                         6391065   \n",
       "expenses                                    34039   \n",
       "from_poi_to_this_person                        32   \n",
       "exercised_stock_options                   5538001   \n",
       "from_messages                                  32   \n",
       "other                                       11350   \n",
       "from_this_person_to_poi                        21   \n",
       "poi                                          True   \n",
       "long_term_incentive                       1617011   \n",
       "shared_receipt_with_poi                      1035   \n",
       "restricted_stock                           853064   \n",
       "director_fees                                 NaN   \n",
       "\n",
       "                                   MORDAUNT KRISTINA M  \\\n",
       "salary                                          267093   \n",
       "to_messages                                        NaN   \n",
       "deferral_payments                                  NaN   \n",
       "total_payments                                  628522   \n",
       "loan_advances                                      NaN   \n",
       "bonus                                           325000   \n",
       "email_address              kristina.mordaunt@enron.com   \n",
       "restricted_stock_deferred                          NaN   \n",
       "deferred_income                                    NaN   \n",
       "total_stock_value                               208510   \n",
       "expenses                                         35018   \n",
       "from_poi_to_this_person                            NaN   \n",
       "exercised_stock_options                            NaN   \n",
       "from_messages                                      NaN   \n",
       "other                                             1411   \n",
       "from_this_person_to_poi                            NaN   \n",
       "poi                                              False   \n",
       "long_term_incentive                                NaN   \n",
       "shared_receipt_with_poi                            NaN   \n",
       "restricted_stock                                208510   \n",
       "director_fees                                      NaN   \n",
       "\n",
       "                                   MEYER ROCKFORD G  \\\n",
       "salary                                          NaN   \n",
       "to_messages                                     232   \n",
       "deferral_payments                           1848227   \n",
       "total_payments                              1848227   \n",
       "loan_advances                                   NaN   \n",
       "bonus                                           NaN   \n",
       "email_address              rockford.meyer@enron.com   \n",
       "restricted_stock_deferred                       NaN   \n",
       "deferred_income                                 NaN   \n",
       "total_stock_value                            955873   \n",
       "expenses                                        NaN   \n",
       "from_poi_to_this_person                           0   \n",
       "exercised_stock_options                      493489   \n",
       "from_messages                                    28   \n",
       "other                                           NaN   \n",
       "from_this_person_to_poi                           0   \n",
       "poi                                           False   \n",
       "long_term_incentive                             NaN   \n",
       "shared_receipt_with_poi                          22   \n",
       "restricted_stock                             462384   \n",
       "director_fees                                   NaN   \n",
       "\n",
       "                                     MCMAHON JEFFREY          HAEDICKE MARK E  \\\n",
       "salary                                        370448                   374125   \n",
       "to_messages                                     2355                     4009   \n",
       "deferral_payments                                NaN                  2157527   \n",
       "total_payments                               4099771                  3859065   \n",
       "loan_advances                                    NaN                      NaN   \n",
       "bonus                                        2600000                  1150000   \n",
       "email_address              jeffrey.mcmahon@enron.com  mark.haedicke@enron.com   \n",
       "restricted_stock_deferred                        NaN                  -329825   \n",
       "deferred_income                                  NaN                  -934484   \n",
       "total_stock_value                            1662855                   803094   \n",
       "expenses                                      137108                    76169   \n",
       "from_poi_to_this_person                           58                      180   \n",
       "exercised_stock_options                      1104054                   608750   \n",
       "from_messages                                     48                     1941   \n",
       "other                                         297353                    52382   \n",
       "from_this_person_to_poi                           26                       61   \n",
       "poi                                            False                    False   \n",
       "long_term_incentive                           694862                   983346   \n",
       "shared_receipt_with_poi                         2228                     1847   \n",
       "restricted_stock                              558801                   524169   \n",
       "director_fees                                    NaN                      NaN   \n",
       "\n",
       "                                PIPER GREGORY F  ... SAVAGE FRANK  \\\n",
       "salary                                   197091  ...          NaN   \n",
       "to_messages                                1238  ...          NaN   \n",
       "deferral_payments                       1130036  ...          NaN   \n",
       "total_payments                          1737629  ...         3750   \n",
       "loan_advances                               NaN  ...          NaN   \n",
       "bonus                                    400000  ...          NaN   \n",
       "email_address              greg.piper@enron.com  ...          NaN   \n",
       "restricted_stock_deferred               -409554  ...          NaN   \n",
       "deferred_income                          -33333  ...      -121284   \n",
       "total_stock_value                        880290  ...          NaN   \n",
       "expenses                                  43057  ...          NaN   \n",
       "from_poi_to_this_person                      61  ...          NaN   \n",
       "exercised_stock_options                  880290  ...          NaN   \n",
       "from_messages                               222  ...          NaN   \n",
       "other                                       778  ...          NaN   \n",
       "from_this_person_to_poi                      48  ...          NaN   \n",
       "poi                                       False  ...        False   \n",
       "long_term_incentive                         NaN  ...          NaN   \n",
       "shared_receipt_with_poi                     742  ...          NaN   \n",
       "restricted_stock                         409554  ...          NaN   \n",
       "director_fees                               NaN  ...       125034   \n",
       "\n",
       "                                IZZO LAWRENCE L          TILNEY ELIZABETH A  \\\n",
       "salary                                    85274                      247338   \n",
       "to_messages                                 496                         460   \n",
       "deferral_payments                           NaN                         NaN   \n",
       "total_payments                          1979596                      399393   \n",
       "loan_advances                               NaN                         NaN   \n",
       "bonus                                       NaN                      300000   \n",
       "email_address              larry.izzo@enron.com  elizabeth.tilney@enron.com   \n",
       "restricted_stock_deferred                   NaN                         NaN   \n",
       "deferred_income                             NaN                     -575000   \n",
       "total_stock_value                       5819980                     1168042   \n",
       "expenses                                  28093                         NaN   \n",
       "from_poi_to_this_person                      28                          10   \n",
       "exercised_stock_options                 2165172                      591250   \n",
       "from_messages                                19                          19   \n",
       "other                                   1553729                      152055   \n",
       "from_this_person_to_poi                       5                          11   \n",
       "poi                                       False                       False   \n",
       "long_term_incentive                      312500                      275000   \n",
       "shared_receipt_with_poi                     437                         379   \n",
       "restricted_stock                        3654808                      576792   \n",
       "director_fees                               NaN                         NaN   \n",
       "\n",
       "                               MARTIN AMANDA K       BUY RICHARD B  \\\n",
       "salary                                  349487              330546   \n",
       "to_messages                               1522                3523   \n",
       "deferral_payments                        85430              649584   \n",
       "total_payments                         8407016             2355702   \n",
       "loan_advances                              NaN                 NaN   \n",
       "bonus                                      NaN              900000   \n",
       "email_address              a..martin@enron.com  rick.buy@enron.com   \n",
       "restricted_stock_deferred                  NaN                 NaN   \n",
       "deferred_income                            NaN             -694862   \n",
       "total_stock_value                      2070306             3444470   \n",
       "expenses                                  8211                 NaN   \n",
       "from_poi_to_this_person                      8                 156   \n",
       "exercised_stock_options                2070306             2542813   \n",
       "from_messages                              230                1053   \n",
       "other                                  2818454              400572   \n",
       "from_this_person_to_poi                      0                  71   \n",
       "poi                                      False               False   \n",
       "long_term_incentive                    5145434              769862   \n",
       "shared_receipt_with_poi                    477                2333   \n",
       "restricted_stock                           NaN              901657   \n",
       "director_fees                              NaN                 NaN   \n",
       "\n",
       "                          GRAMM WENDY L          CAUSEY RICHARD A  \\\n",
       "salary                              NaN                    415189   \n",
       "to_messages                         NaN                      1892   \n",
       "deferral_payments                   NaN                       NaN   \n",
       "total_payments                   119292                   1868758   \n",
       "loan_advances                       NaN                       NaN   \n",
       "bonus                               NaN                   1000000   \n",
       "email_address                       NaN  richard.causey@enron.com   \n",
       "restricted_stock_deferred           NaN                       NaN   \n",
       "deferred_income                     NaN                   -235000   \n",
       "total_stock_value                   NaN                   2502063   \n",
       "expenses                            NaN                     30674   \n",
       "from_poi_to_this_person             NaN                        58   \n",
       "exercised_stock_options             NaN                       NaN   \n",
       "from_messages                       NaN                        49   \n",
       "other                               NaN                    307895   \n",
       "from_this_person_to_poi             NaN                        12   \n",
       "poi                               False                      True   \n",
       "long_term_incentive                 NaN                    350000   \n",
       "shared_receipt_with_poi             NaN                      1585   \n",
       "restricted_stock                    NaN                   2502063   \n",
       "director_fees                    119292                       NaN   \n",
       "\n",
       "                                   TAYLOR MITCHELL S    DONAHUE JR JEFFREY M  \\\n",
       "salary                                        265214                  278601   \n",
       "to_messages                                      533                     865   \n",
       "deferral_payments                             227449                     NaN   \n",
       "total_payments                               1092663                  875760   \n",
       "loan_advances                                    NaN                     NaN   \n",
       "bonus                                         600000                  800000   \n",
       "email_address              mitchell.taylor@enron.com  jeff.donahue@enron.com   \n",
       "restricted_stock_deferred                        NaN                     NaN   \n",
       "deferred_income                                  NaN                 -300000   \n",
       "total_stock_value                            3745048                 1080988   \n",
       "expenses                                         NaN                   96268   \n",
       "from_poi_to_this_person                            0                     188   \n",
       "exercised_stock_options                      3181250                  765920   \n",
       "from_messages                                     29                      22   \n",
       "other                                            NaN                     891   \n",
       "from_this_person_to_poi                            0                      11   \n",
       "poi                                            False                   False   \n",
       "long_term_incentive                              NaN                     NaN   \n",
       "shared_receipt_with_poi                          300                     772   \n",
       "restricted_stock                              563798                  315068   \n",
       "director_fees                                    NaN                     NaN   \n",
       "\n",
       "                                GLISAN JR BEN F  \n",
       "salary                                   274975  \n",
       "to_messages                                 873  \n",
       "deferral_payments                           NaN  \n",
       "total_payments                          1272284  \n",
       "loan_advances                               NaN  \n",
       "bonus                                    600000  \n",
       "email_address              ben.glisan@enron.com  \n",
       "restricted_stock_deferred                   NaN  \n",
       "deferred_income                             NaN  \n",
       "total_stock_value                        778546  \n",
       "expenses                                 125978  \n",
       "from_poi_to_this_person                      52  \n",
       "exercised_stock_options                  384728  \n",
       "from_messages                                16  \n",
       "other                                    200308  \n",
       "from_this_person_to_poi                       6  \n",
       "poi                                        True  \n",
       "long_term_incentive                       71023  \n",
       "shared_receipt_with_poi                     874  \n",
       "restricted_stock                         393818  \n",
       "director_fees                               NaN  \n",
       "\n",
       "[21 rows x 146 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>365788</td>\n",
       "      <td>807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>585062</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>1740</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>5634343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>10623258</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350000</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>6678735</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4890344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>651850</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>243293</td>\n",
       "      <td>1045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500000</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>6391065</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>5538001</td>\n",
       "      <td>32</td>\n",
       "      <td>11350</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>1617011</td>\n",
       "      <td>1035</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORDAUNT KRISTINA M</th>\n",
       "      <td>267093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325000</td>\n",
       "      <td>kristina.mordaunt@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208510</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEYER ROCKFORD G</th>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>1848227</td>\n",
       "      <td>1848227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rockford.meyer@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>493489</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>462384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCMAHON JEFFREY</th>\n",
       "      <td>370448</td>\n",
       "      <td>2355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4099771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600000</td>\n",
       "      <td>jeffrey.mcmahon@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1662855</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>1104054</td>\n",
       "      <td>48</td>\n",
       "      <td>297353</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>694862</td>\n",
       "      <td>2228</td>\n",
       "      <td>558801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAEDICKE MARK E</th>\n",
       "      <td>374125</td>\n",
       "      <td>4009</td>\n",
       "      <td>2157527</td>\n",
       "      <td>3859065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1150000</td>\n",
       "      <td>mark.haedicke@enron.com</td>\n",
       "      <td>-329825</td>\n",
       "      <td>-934484</td>\n",
       "      <td>803094</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>608750</td>\n",
       "      <td>1941</td>\n",
       "      <td>52382</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>983346</td>\n",
       "      <td>1847</td>\n",
       "      <td>524169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIPER GREGORY F</th>\n",
       "      <td>197091</td>\n",
       "      <td>1238</td>\n",
       "      <td>1130036</td>\n",
       "      <td>1737629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000</td>\n",
       "      <td>greg.piper@enron.com</td>\n",
       "      <td>-409554</td>\n",
       "      <td>-33333</td>\n",
       "      <td>880290</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>880290</td>\n",
       "      <td>222</td>\n",
       "      <td>778</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>742</td>\n",
       "      <td>409554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     salary to_messages deferral_payments total_payments  \\\n",
       "METTS MARK           365788         807               NaN        1061827   \n",
       "BAXTER JOHN C        267102         NaN           1295738        5634343   \n",
       "ELLIOTT STEVEN       170941         NaN               NaN         211725   \n",
       "CORDES WILLIAM R        NaN         764               NaN            NaN   \n",
       "HANNON KEVIN P       243293        1045               NaN         288682   \n",
       "MORDAUNT KRISTINA M  267093         NaN               NaN         628522   \n",
       "MEYER ROCKFORD G        NaN         232           1848227        1848227   \n",
       "MCMAHON JEFFREY      370448        2355               NaN        4099771   \n",
       "HAEDICKE MARK E      374125        4009           2157527        3859065   \n",
       "PIPER GREGORY F      197091        1238           1130036        1737629   \n",
       "\n",
       "                    loan_advances    bonus                email_address  \\\n",
       "METTS MARK                    NaN   600000         mark.metts@enron.com   \n",
       "BAXTER JOHN C                 NaN  1200000                          NaN   \n",
       "ELLIOTT STEVEN                NaN   350000     steven.elliott@enron.com   \n",
       "CORDES WILLIAM R              NaN      NaN        bill.cordes@enron.com   \n",
       "HANNON KEVIN P                NaN  1500000       kevin.hannon@enron.com   \n",
       "MORDAUNT KRISTINA M           NaN   325000  kristina.mordaunt@enron.com   \n",
       "MEYER ROCKFORD G              NaN      NaN     rockford.meyer@enron.com   \n",
       "MCMAHON JEFFREY               NaN  2600000    jeffrey.mcmahon@enron.com   \n",
       "HAEDICKE MARK E               NaN  1150000      mark.haedicke@enron.com   \n",
       "PIPER GREGORY F               NaN   400000         greg.piper@enron.com   \n",
       "\n",
       "                    restricted_stock_deferred deferred_income  \\\n",
       "METTS MARK                                NaN             NaN   \n",
       "BAXTER JOHN C                             NaN        -1386055   \n",
       "ELLIOTT STEVEN                            NaN         -400729   \n",
       "CORDES WILLIAM R                          NaN             NaN   \n",
       "HANNON KEVIN P                            NaN        -3117011   \n",
       "MORDAUNT KRISTINA M                       NaN             NaN   \n",
       "MEYER ROCKFORD G                          NaN             NaN   \n",
       "MCMAHON JEFFREY                           NaN             NaN   \n",
       "HAEDICKE MARK E                       -329825         -934484   \n",
       "PIPER GREGORY F                       -409554          -33333   \n",
       "\n",
       "                    total_stock_value  ... from_poi_to_this_person  \\\n",
       "METTS MARK                     585062  ...                      38   \n",
       "BAXTER JOHN C                10623258  ...                     NaN   \n",
       "ELLIOTT STEVEN                6678735  ...                     NaN   \n",
       "CORDES WILLIAM R              1038185  ...                      10   \n",
       "HANNON KEVIN P                6391065  ...                      32   \n",
       "MORDAUNT KRISTINA M            208510  ...                     NaN   \n",
       "MEYER ROCKFORD G               955873  ...                       0   \n",
       "MCMAHON JEFFREY               1662855  ...                      58   \n",
       "HAEDICKE MARK E                803094  ...                     180   \n",
       "PIPER GREGORY F                880290  ...                      61   \n",
       "\n",
       "                    exercised_stock_options from_messages    other  \\\n",
       "METTS MARK                              NaN            29     1740   \n",
       "BAXTER JOHN C                       6680544           NaN  2660303   \n",
       "ELLIOTT STEVEN                      4890344           NaN    12961   \n",
       "CORDES WILLIAM R                     651850            12      NaN   \n",
       "HANNON KEVIN P                      5538001            32    11350   \n",
       "MORDAUNT KRISTINA M                     NaN           NaN     1411   \n",
       "MEYER ROCKFORD G                     493489            28      NaN   \n",
       "MCMAHON JEFFREY                     1104054            48   297353   \n",
       "HAEDICKE MARK E                      608750          1941    52382   \n",
       "PIPER GREGORY F                      880290           222      778   \n",
       "\n",
       "                    from_this_person_to_poi    poi  long_term_incentive  \\\n",
       "METTS MARK                                1  False                  NaN   \n",
       "BAXTER JOHN C                           NaN  False              1586055   \n",
       "ELLIOTT STEVEN                          NaN  False                  NaN   \n",
       "CORDES WILLIAM R                          0  False                  NaN   \n",
       "HANNON KEVIN P                           21   True              1617011   \n",
       "MORDAUNT KRISTINA M                     NaN  False                  NaN   \n",
       "MEYER ROCKFORD G                          0  False                  NaN   \n",
       "MCMAHON JEFFREY                          26  False               694862   \n",
       "HAEDICKE MARK E                          61  False               983346   \n",
       "PIPER GREGORY F                          48  False                  NaN   \n",
       "\n",
       "                    shared_receipt_with_poi restricted_stock director_fees  \n",
       "METTS MARK                              702           585062           NaN  \n",
       "BAXTER JOHN C                           NaN          3942714           NaN  \n",
       "ELLIOTT STEVEN                          NaN          1788391           NaN  \n",
       "CORDES WILLIAM R                         58           386335           NaN  \n",
       "HANNON KEVIN P                         1035           853064           NaN  \n",
       "MORDAUNT KRISTINA M                     NaN           208510           NaN  \n",
       "MEYER ROCKFORD G                         22           462384           NaN  \n",
       "MCMAHON JEFFREY                        2228           558801           NaN  \n",
       "HAEDICKE MARK E                        1847           524169           NaN  \n",
       "PIPER GREGORY F                         742           409554           NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.head(10) #shows first 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SAVAGE FRANK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-121284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IZZO LAWRENCE L</th>\n",
       "      <td>85274</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>larry.izzo@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5819980</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>2165172</td>\n",
       "      <td>19</td>\n",
       "      <td>1553729</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>312500</td>\n",
       "      <td>437</td>\n",
       "      <td>3654808</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TILNEY ELIZABETH A</th>\n",
       "      <td>247338</td>\n",
       "      <td>460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000</td>\n",
       "      <td>elizabeth.tilney@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-575000</td>\n",
       "      <td>1168042</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>591250</td>\n",
       "      <td>19</td>\n",
       "      <td>152055</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>275000</td>\n",
       "      <td>379</td>\n",
       "      <td>576792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARTIN AMANDA K</th>\n",
       "      <td>349487</td>\n",
       "      <td>1522</td>\n",
       "      <td>85430</td>\n",
       "      <td>8407016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a..martin@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2070306</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2070306</td>\n",
       "      <td>230</td>\n",
       "      <td>2818454</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5145434</td>\n",
       "      <td>477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUY RICHARD B</th>\n",
       "      <td>330546</td>\n",
       "      <td>3523</td>\n",
       "      <td>649584</td>\n",
       "      <td>2355702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000</td>\n",
       "      <td>rick.buy@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-694862</td>\n",
       "      <td>3444470</td>\n",
       "      <td>...</td>\n",
       "      <td>156</td>\n",
       "      <td>2542813</td>\n",
       "      <td>1053</td>\n",
       "      <td>400572</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "      <td>769862</td>\n",
       "      <td>2333</td>\n",
       "      <td>901657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>415189</td>\n",
       "      <td>1892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1868758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "      <td>richard.causey@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-235000</td>\n",
       "      <td>2502063</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>307895</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>350000</td>\n",
       "      <td>1585</td>\n",
       "      <td>2502063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>265214</td>\n",
       "      <td>533</td>\n",
       "      <td>227449</td>\n",
       "      <td>1092663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>mitchell.taylor@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3745048</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3181250</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>563798</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>278601</td>\n",
       "      <td>865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000</td>\n",
       "      <td>jeff.donahue@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300000</td>\n",
       "      <td>1080988</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>765920</td>\n",
       "      <td>22</td>\n",
       "      <td>891</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772</td>\n",
       "      <td>315068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>274975</td>\n",
       "      <td>873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>ben.glisan@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778546</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>384728</td>\n",
       "      <td>16</td>\n",
       "      <td>200308</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>71023</td>\n",
       "      <td>874</td>\n",
       "      <td>393818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      salary to_messages deferral_payments total_payments  \\\n",
       "SAVAGE FRANK             NaN         NaN               NaN           3750   \n",
       "IZZO LAWRENCE L        85274         496               NaN        1979596   \n",
       "TILNEY ELIZABETH A    247338         460               NaN         399393   \n",
       "MARTIN AMANDA K       349487        1522             85430        8407016   \n",
       "BUY RICHARD B         330546        3523            649584        2355702   \n",
       "GRAMM WENDY L            NaN         NaN               NaN         119292   \n",
       "CAUSEY RICHARD A      415189        1892               NaN        1868758   \n",
       "TAYLOR MITCHELL S     265214         533            227449        1092663   \n",
       "DONAHUE JR JEFFREY M  278601         865               NaN         875760   \n",
       "GLISAN JR BEN F       274975         873               NaN        1272284   \n",
       "\n",
       "                     loan_advances    bonus               email_address  \\\n",
       "SAVAGE FRANK                   NaN      NaN                         NaN   \n",
       "IZZO LAWRENCE L                NaN      NaN        larry.izzo@enron.com   \n",
       "TILNEY ELIZABETH A             NaN   300000  elizabeth.tilney@enron.com   \n",
       "MARTIN AMANDA K                NaN      NaN         a..martin@enron.com   \n",
       "BUY RICHARD B                  NaN   900000          rick.buy@enron.com   \n",
       "GRAMM WENDY L                  NaN      NaN                         NaN   \n",
       "CAUSEY RICHARD A               NaN  1000000    richard.causey@enron.com   \n",
       "TAYLOR MITCHELL S              NaN   600000   mitchell.taylor@enron.com   \n",
       "DONAHUE JR JEFFREY M           NaN   800000      jeff.donahue@enron.com   \n",
       "GLISAN JR BEN F                NaN   600000        ben.glisan@enron.com   \n",
       "\n",
       "                     restricted_stock_deferred deferred_income  \\\n",
       "SAVAGE FRANK                               NaN         -121284   \n",
       "IZZO LAWRENCE L                            NaN             NaN   \n",
       "TILNEY ELIZABETH A                         NaN         -575000   \n",
       "MARTIN AMANDA K                            NaN             NaN   \n",
       "BUY RICHARD B                              NaN         -694862   \n",
       "GRAMM WENDY L                              NaN             NaN   \n",
       "CAUSEY RICHARD A                           NaN         -235000   \n",
       "TAYLOR MITCHELL S                          NaN             NaN   \n",
       "DONAHUE JR JEFFREY M                       NaN         -300000   \n",
       "GLISAN JR BEN F                            NaN             NaN   \n",
       "\n",
       "                     total_stock_value  ... from_poi_to_this_person  \\\n",
       "SAVAGE FRANK                       NaN  ...                     NaN   \n",
       "IZZO LAWRENCE L                5819980  ...                      28   \n",
       "TILNEY ELIZABETH A             1168042  ...                      10   \n",
       "MARTIN AMANDA K                2070306  ...                       8   \n",
       "BUY RICHARD B                  3444470  ...                     156   \n",
       "GRAMM WENDY L                      NaN  ...                     NaN   \n",
       "CAUSEY RICHARD A               2502063  ...                      58   \n",
       "TAYLOR MITCHELL S              3745048  ...                       0   \n",
       "DONAHUE JR JEFFREY M           1080988  ...                     188   \n",
       "GLISAN JR BEN F                 778546  ...                      52   \n",
       "\n",
       "                     exercised_stock_options from_messages    other  \\\n",
       "SAVAGE FRANK                             NaN           NaN      NaN   \n",
       "IZZO LAWRENCE L                      2165172            19  1553729   \n",
       "TILNEY ELIZABETH A                    591250            19   152055   \n",
       "MARTIN AMANDA K                      2070306           230  2818454   \n",
       "BUY RICHARD B                        2542813          1053   400572   \n",
       "GRAMM WENDY L                            NaN           NaN      NaN   \n",
       "CAUSEY RICHARD A                         NaN            49   307895   \n",
       "TAYLOR MITCHELL S                    3181250            29      NaN   \n",
       "DONAHUE JR JEFFREY M                  765920            22      891   \n",
       "GLISAN JR BEN F                       384728            16   200308   \n",
       "\n",
       "                     from_this_person_to_poi    poi  long_term_incentive  \\\n",
       "SAVAGE FRANK                             NaN  False                  NaN   \n",
       "IZZO LAWRENCE L                            5  False               312500   \n",
       "TILNEY ELIZABETH A                        11  False               275000   \n",
       "MARTIN AMANDA K                            0  False              5145434   \n",
       "BUY RICHARD B                             71  False               769862   \n",
       "GRAMM WENDY L                            NaN  False                  NaN   \n",
       "CAUSEY RICHARD A                          12   True               350000   \n",
       "TAYLOR MITCHELL S                          0  False                  NaN   \n",
       "DONAHUE JR JEFFREY M                      11  False                  NaN   \n",
       "GLISAN JR BEN F                            6   True                71023   \n",
       "\n",
       "                     shared_receipt_with_poi restricted_stock director_fees  \n",
       "SAVAGE FRANK                             NaN              NaN        125034  \n",
       "IZZO LAWRENCE L                          437          3654808           NaN  \n",
       "TILNEY ELIZABETH A                       379           576792           NaN  \n",
       "MARTIN AMANDA K                          477              NaN           NaN  \n",
       "BUY RICHARD B                           2333           901657           NaN  \n",
       "GRAMM WENDY L                            NaN              NaN        119292  \n",
       "CAUSEY RICHARD A                        1585          2502063           NaN  \n",
       "TAYLOR MITCHELL S                        300           563798           NaN  \n",
       "DONAHUE JR JEFFREY M                     772           315068           NaN  \n",
       "GLISAN JR BEN F                          874           393818           NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.tail(10) #shows last 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.shape #analyze the shape of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   salary                     146 non-null    object\n",
      " 1   to_messages                146 non-null    object\n",
      " 2   deferral_payments          146 non-null    object\n",
      " 3   total_payments             146 non-null    object\n",
      " 4   loan_advances              146 non-null    object\n",
      " 5   bonus                      146 non-null    object\n",
      " 6   email_address              146 non-null    object\n",
      " 7   restricted_stock_deferred  146 non-null    object\n",
      " 8   deferred_income            146 non-null    object\n",
      " 9   total_stock_value          146 non-null    object\n",
      " 10  expenses                   146 non-null    object\n",
      " 11  from_poi_to_this_person    146 non-null    object\n",
      " 12  exercised_stock_options    146 non-null    object\n",
      " 13  from_messages              146 non-null    object\n",
      " 14  other                      146 non-null    object\n",
      " 15  from_this_person_to_poi    146 non-null    object\n",
      " 16  poi                        146 non-null    bool  \n",
      " 17  long_term_incentive        146 non-null    object\n",
      " 18  shared_receipt_with_poi    146 non-null    object\n",
      " 19  restricted_stock           146 non-null    object\n",
      " 20  director_fees              146 non-null    object\n",
      "dtypes: bool(1), object(20)\n",
      "memory usage: 29.1+ KB\n",
      "There are a total of 146 people in the dataset.\n",
      "Out of which 18 are POI and 128 Non-POI.\n",
      "Total number of email plus financial features are 20. 'poi' column is our label.\n"
     ]
    }
   ],
   "source": [
    "enron_data.info() \n",
    "\n",
    "print (\"There are a total of {} people in the dataset.\" .format(len(enron_data.index)))\n",
    "print (\"Out of which {} are POI and {} Non-POI.\" .format(enron_data['poi'].value_counts()[True], \n",
    "                                                 enron_data['poi'].value_counts()[False]))\n",
    "print (\"Total number of email plus financial features are {}. 'poi' column is our label.\" .format(len(enron_data.columns)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>95</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>65</td>\n",
       "      <td>93</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>107</td>\n",
       "      <td>21</td>\n",
       "      <td>142</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary to_messages deferral_payments total_payments loan_advances  \\\n",
       "count     146         146               146            146           146   \n",
       "unique     95          87                40            126             5   \n",
       "top       NaN         NaN               NaN            NaN           NaN   \n",
       "freq       51          60               107             21           142   \n",
       "\n",
       "       bonus email_address restricted_stock_deferred deferred_income  \\\n",
       "count    146           146                       146             146   \n",
       "unique    42           112                        19              45   \n",
       "top      NaN           NaN                       NaN             NaN   \n",
       "freq      64            35                       128              97   \n",
       "\n",
       "       total_stock_value  ... from_poi_to_this_person exercised_stock_options  \\\n",
       "count                146  ...                     146                     146   \n",
       "unique               125  ...                      58                     102   \n",
       "top                  NaN  ...                     NaN                     NaN   \n",
       "freq                  20  ...                      60                      44   \n",
       "\n",
       "       from_messages other from_this_person_to_poi    poi long_term_incentive  \\\n",
       "count            146   146                     146    146                 146   \n",
       "unique            65    93                      42      2                  53   \n",
       "top              NaN   NaN                     NaN  False                 NaN   \n",
       "freq              60    53                      60    128                  80   \n",
       "\n",
       "       shared_receipt_with_poi restricted_stock director_fees  \n",
       "count                      146              146           146  \n",
       "unique                      84               98            18  \n",
       "top                        NaN              NaN           NaN  \n",
       "freq                        60               36           129  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Analysis of one of the POI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample data for one of the Top executives - Jeffrey Skilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 5600000,\n",
      " 'deferral_payments': 'NaN',\n",
      " 'deferred_income': 'NaN',\n",
      " 'director_fees': 'NaN',\n",
      " 'email_address': 'jeff.skilling@enron.com',\n",
      " 'exercised_stock_options': 19250000,\n",
      " 'expenses': 29336,\n",
      " 'from_messages': 108,\n",
      " 'from_poi_to_this_person': 88,\n",
      " 'from_this_person_to_poi': 30,\n",
      " 'loan_advances': 'NaN',\n",
      " 'long_term_incentive': 1920000,\n",
      " 'other': 22122,\n",
      " 'poi': True,\n",
      " 'restricted_stock': 6843672,\n",
      " 'restricted_stock_deferred': 'NaN',\n",
      " 'salary': 1111258,\n",
      " 'shared_receipt_with_poi': 2042,\n",
      " 'to_messages': 3627,\n",
      " 'total_payments': 8682716,\n",
      " 'total_stock_value': 26093672}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_dict[\"SKILLING JEFFREY K\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Values, NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat in data_dict: \n",
    "    data_e = data_dict[feat]\n",
    "    if data_e['deferred_income'] == 'NaN' :\n",
    "        data_e['deferred_income'] = 0\n",
    "        \n",
    "    if data_e['email_address'] == 'NaN' :\n",
    "        data_e['email_address'] = 0     \n",
    "        \n",
    "    if data_e['other'] == 'NaN' :\n",
    "        data_e['other'] = 0\n",
    "        \n",
    "    if data_e['restricted_stock'] == 'NaN' :\n",
    "        data_e['restricted_stock'] = 0    \n",
    "        \n",
    "    if data_e['shared_receipt_with_poi'] == 'NaN' :\n",
    "        data_e['shared_receipt_with_poi'] = 0\n",
    "        \n",
    "    if data_e['deferral_payments'] == 'NaN' :\n",
    "        data_e['deferral_payments'] = 0 \n",
    "        \n",
    "    if data_e['loan_advances'] == 'NaN':\n",
    "        data_e['loan_advances'] = 0 \n",
    "        \n",
    "    if data_e['bonus'] == 'NaN' :\n",
    "        data_e['bonus'] = 0\n",
    "        \n",
    "    if data_e['restricted_stock_deferred'] == 'NaN':\n",
    "        data_e['restricted_stock_deferred'] = 0\n",
    "        \n",
    "    if data_e['total_stock_value'] == 'NaN' :\n",
    "        data_e['total_stock_value'] = 0\n",
    "        \n",
    "    if data_e['expenses'] == 'NaN' :\n",
    "        data_e['expenses'] = 0\n",
    "        \n",
    "    if data_e['exercised_stock_options'] == 'NaN' :\n",
    "        data_e['exercised_stock_options'] = 0   \n",
    "        \n",
    "    if data_e['long_term_incentive'] == 'NaN' :\n",
    "        data_e['long_term_incentive'] = 0\n",
    "        \n",
    "    if data_e['director_fees'] == 'NaN' :\n",
    "        data_e['director_fees'] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific Analysis of LOCKHART EUGENE E and BAXTER JOHN C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 0,\n",
      " 'deferral_payments': 0,\n",
      " 'deferred_income': 0,\n",
      " 'director_fees': 0,\n",
      " 'email_address': 0,\n",
      " 'exercised_stock_options': 0,\n",
      " 'expenses': 0,\n",
      " 'from_messages': 'NaN',\n",
      " 'from_poi_to_this_person': 'NaN',\n",
      " 'from_this_person_to_poi': 'NaN',\n",
      " 'loan_advances': 0,\n",
      " 'long_term_incentive': 0,\n",
      " 'other': 0,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 0,\n",
      " 'restricted_stock_deferred': 0,\n",
      " 'salary': 'NaN',\n",
      " 'shared_receipt_with_poi': 0,\n",
      " 'to_messages': 'NaN',\n",
      " 'total_payments': 'NaN',\n",
      " 'total_stock_value': 0}\n",
      "{'bonus': 1200000,\n",
      " 'deferral_payments': 1295738,\n",
      " 'deferred_income': -1386055,\n",
      " 'director_fees': 0,\n",
      " 'email_address': 0,\n",
      " 'exercised_stock_options': 6680544,\n",
      " 'expenses': 11200,\n",
      " 'from_messages': 'NaN',\n",
      " 'from_poi_to_this_person': 'NaN',\n",
      " 'from_this_person_to_poi': 'NaN',\n",
      " 'loan_advances': 0,\n",
      " 'long_term_incentive': 1586055,\n",
      " 'other': 2660303,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 3942714,\n",
      " 'restricted_stock_deferred': 0,\n",
      " 'salary': 267102,\n",
      " 'shared_receipt_with_poi': 0,\n",
      " 'to_messages': 'NaN',\n",
      " 'total_payments': 5634343,\n",
      " 'total_stock_value': 10623258}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data_dict[\"LOCKHART EUGENE E\"])\n",
    "pprint.pprint(data_dict[\"BAXTER JOHN C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eugene Lockhart only has NaN values, so it is better to remove it as an outlier.\n",
    "John Baxter has a lot of missing values especially on features we want to keep for our model.\n",
    "So it also better to remove it as an outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/plotly/tools.py:461: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plotly.com/~Praline96/405.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa1f57b1f70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conda install -c plotly plotly chart-studio\n",
    "\n",
    "chart_studio.tools.set_credentials_file(username='Praline96', api_key='kXkhT1CwKs4MSwsl5d3u')\n",
    "\n",
    "# Make scatterplot before outlier removal\n",
    "trace0 = go.Scatter(\n",
    "    x=enron_data.salary,\n",
    "    y=enron_data.bonus,\n",
    "    text = enron_data.index,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "# Remove Outliers\n",
    "enron_data.drop(['TOTAL'], axis = 0, inplace= True)\n",
    "enron_data.drop(['THE TRAVEL AGENCY IN THE PARK'], axis = 0, inplace= True)\n",
    "enron_data.drop(['LOCKHART EUGENE E'], axis = 0, inplace= True)\n",
    "\n",
    "\n",
    "# Make scatterplot after outliers removal\n",
    "trace1 = go.Scatter(\n",
    "    x=enron_data.salary,\n",
    "    y=enron_data.bonus,\n",
    "    text = enron_data.index,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "# Layout the plots together side by side\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=('Before outliers removal', 'After outliers removal'))\n",
    "\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='salary')\n",
    "fig['layout']['xaxis2'].update(title='salary')\n",
    "\n",
    "fig['layout']['yaxis1'].update(title='bonus')\n",
    "fig['layout']['yaxis2'].update(title='bonus')\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used visualization to find outliers because it is the clearest way to find them. \n",
    "When plotting salary and  bonus, we found an outlier : \"TOTAL\" \n",
    "We found one more outlier which is not corresponding with a name of a real person \"THE TRAVEL AGENCY IN THE PARK\". \n",
    "We dropped these outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/plotly/tools.py:461: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://plotly.com/~Praline96/407.embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa1f54a2730>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make scatterplot before outlier removal\n",
    "trace0 = go.Scatter(\n",
    "    x=enron_data.salary,\n",
    "    y=enron_data.bonus,\n",
    "    text = enron_data.index,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "# Remove Outliers\n",
    "enron_data.drop(['LAVORATO JOHN J'], axis = 0, inplace= True)\n",
    "enron_data.drop(['FREVERT MARK A'], axis = 0, inplace= True)\n",
    "enron_data.drop(['BAXTER JOHN C'], axis = 0, inplace= True)\n",
    "enron_data.drop(['WHALLEY LAWRENCE G'], axis = 0, inplace= True)\n",
    "\n",
    "\n",
    "# Make scatterplot after outliers removal\n",
    "trace1 = go.Scatter(\n",
    "    x=enron_data.salary,\n",
    "    y=enron_data.bonus,\n",
    "    text = enron_data.index,\n",
    "    mode = 'markers'\n",
    ")\n",
    "\n",
    "# Layout the plots together side by side\n",
    "fig = tools.make_subplots(rows=1, cols=2, subplot_titles=('Before outliers removal', 'After outliers removal'))\n",
    "\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='salary')\n",
    "fig['layout']['xaxis2'].update(title='salary')\n",
    "\n",
    "fig['layout']['yaxis1'].update(title='bonus')\n",
    "fig['layout']['yaxis2'].update(title='bonus')\n",
    "\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the plot \"Before outliers removal\" we decided to remove the extrems values(non-POI) and after analysing\n",
    "the board of the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers on the data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salary': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'deferral_payments': 0,\n",
       " 'total_payments': 'NaN',\n",
       " 'loan_advances': 0,\n",
       " 'bonus': 0,\n",
       " 'email_address': 0,\n",
       " 'restricted_stock_deferred': 0,\n",
       " 'deferred_income': 0,\n",
       " 'total_stock_value': 0,\n",
       " 'expenses': 0,\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'exercised_stock_options': 0,\n",
       " 'from_messages': 'NaN',\n",
       " 'other': 0,\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'poi': False,\n",
       " 'long_term_incentive': 0,\n",
       " 'shared_receipt_with_poi': 0,\n",
       " 'restricted_stock': 0,\n",
       " 'director_fees': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('FREVERT MARK A')\n",
    "data_dict.pop('LAVORATO JOHN J')\n",
    "data_dict.pop('WHALLEY LAWRENCE G')\n",
    "data_dict.pop('BAXTER JOHN C')\n",
    "data_dict.pop('TOTAL')\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK')\n",
    "data_dict.pop('LOCKHART EUGENE E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create new feature(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new copies of dataset for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering, new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal, getcontext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some new features of interest to the list of the features. We will make a function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'bonus', 'deferral_payments', 'deferred_income', 'director_fees', 'exercised_stock_options', 'expenses', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'salary', 'total_payments', 'total_stock_value', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'to_messages', 'poi_ratio', 'fraction_to_poi', 'fraction_from_poi', 'bonus_to_salary', 'bonus_to_total']\n"
     ]
    }
   ],
   "source": [
    "def add_poi_ratio(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email interaction with pois \"\"\"\n",
    "    fields = ['to_messages', 'from_messages',\n",
    "              'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['to_messages'] +\\\n",
    "                             person['from_messages']\n",
    "            poi_messages = person['from_poi_to_this_person'] +\\\n",
    "                           person['from_this_person_to_poi']\n",
    "            person['poi_ratio'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['poi_ratio'] = 'NaN'\n",
    "    features_list += ['poi_ratio']\n",
    "\n",
    "def add_fraction_to_poi(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email fraction_to_poi \"\"\"\n",
    "    fields = ['from_messages', 'from_this_person_to_poi']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['from_messages']\n",
    "            poi_messages =   person['from_this_person_to_poi']\n",
    "            person['fraction_to_poi'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['fraction_to_poi'] = 'NaN'\n",
    "    features_list += ['fraction_to_poi']\n",
    "\n",
    "def add_fraction_from_poi(data_dict, features_list):\n",
    "    \"\"\" mutates data dict to add proportion of email fraction_from_poi \"\"\"\n",
    "    fields = ['to_messages', 'from_poi_to_this_person']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "            total_messages = person['to_messages']\n",
    "            poi_messages =   person['from_poi_to_this_person']\n",
    "            person['fraction_from_poi'] = float(poi_messages) / total_messages\n",
    "        else:\n",
    "            person['fraction_from_poi'] = 'NaN'\n",
    "    features_list += ['fraction_from_poi']\n",
    "    \n",
    "def add_bonus_to_salary(data_dict, features_list):\n",
    "    fields = ['bonus', 'salary']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "           Total_bonus = person['bonus']\n",
    "           Total_salary = person['salary']\n",
    "           person['bonus_to_salary'] = float(Total_bonus) / Total_salary\n",
    "        else:\n",
    "            person['bonus_to_salary'] = 'NaN'\n",
    "    features_list += ['bonus_to_salary']\n",
    "\n",
    "def add_bonus_to_total(data_dict, features_list):\n",
    "    fields = ['bonus', 'total_payments']\n",
    "    for record in data_dict:\n",
    "        person = data_dict[record]\n",
    "        is_valid = True\n",
    "        for field in fields:\n",
    "            if person[field] == 'NaN':\n",
    "                is_valid = False\n",
    "        if is_valid:\n",
    "           Total_bonus2 = person['bonus']\n",
    "           Total_payments2 = person['total_payments']\n",
    "           person['bonus_to_total'] = float(Total_bonus2) / Total_payments2\n",
    "        else:\n",
    "            person['bonus_to_total'] = 'NaN'\n",
    "    features_list += ['bonus_to_total']   \n",
    "\n",
    "my_feature_list = features_list\n",
    "\n",
    "#Adding them to the features list\n",
    "add_poi_ratio(data_dict, my_feature_list)\n",
    "add_fraction_to_poi(data_dict, my_feature_list)\n",
    "add_fraction_from_poi(data_dict, my_feature_list)\n",
    "add_bonus_to_salary(data_dict, my_feature_list)\n",
    "add_bonus_to_total(data_dict, my_feature_list)\n",
    "print (my_feature_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created 3 features with the email_features_list and 2 features with the financial_features_list\n",
    "* poi_ratio\n",
    "* fraction_to_poi\n",
    "* fraction_from_poi\n",
    "* bonus_to_salary\n",
    "* bonus_to_total\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new copies of feature list for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_list = features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get K-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best(data_dict, features_list, k):\n",
    "    \"\"\" runs scikit-learn's SelectKBest feature selection\n",
    "        returns dict where keys=features, values=scores\n",
    "    \"\"\"\n",
    "    data = featureFormat(data_dict, features_list)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "\n",
    "    k_best = SelectKBest(k=k)\n",
    "    k_best.fit(features, labels)\n",
    "    scores = k_best.scores_\n",
    "    print(scores)\n",
    "    unsorted_pairs = zip(features_list[1:], scores)\n",
    "    sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "    k_best_features = dict(sorted_pairs[:k])\n",
    "    print (\"{0} best features: {1}\\n\".format(k, k_best_features.keys(), scores))\n",
    "    return k_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.7816913   0.06233576 16.95719491  2.20445373 26.5605672   6.27032312\n",
      "  7.00482086 12.56239963  7.79759949 10.37309462  0.06764556 25.10415132\n",
      "  9.53332413 26.46587154  0.13885137 11.74247165  3.34065915 12.09832639\n",
      "  2.27518447  5.76594457 16.27553035  3.43989738 16.78134655 20.61205177]\n",
      "10 best features: dict_keys(['bonus', 'exercised_stock_options', 'total_stock_value', 'salary', 'bonus_to_total', 'deferred_income', 'bonus_to_salary', 'fraction_to_poi', 'long_term_incentive', 'shared_receipt_with_poi'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_features = get_k_best(my_dataset, my_feature_list, num_features)\n",
    "\n",
    "my_feature_list = [target_label] + list(set(best_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 selected features: ['total_stock_value', 'bonus_to_total', 'bonus', 'shared_receipt_with_poi', 'long_term_incentive', 'salary', 'deferred_income', 'exercised_stock_options', 'bonus_to_salary', 'fraction_to_poi']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"{0} selected features: {1}\\n\".format(len(my_feature_list) - 1, my_feature_list[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the features specified in features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features via min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 Using Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "g_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "d_clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "l_clf = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(C=1e-08, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, \n",
    "max_iter=100, multi_class='ovr', penalty='l2', random_state=42, solver='liblinear', tol=0.001, verbose=0))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_clf = KMeans(n_clusters=2, tol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth = 5,max_features = 'sqrt',n_estimators = 10, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, features, labels, num_iters=1000, test_size=0.3):\n",
    "    print (clf)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    first = True\n",
    "    for trial in range(num_iters):\n",
    "        features_train, features_test, labels_train, labels_test =\\\n",
    "            train_test_split(features, labels, test_size=test_size)\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        accuracy.append(accuracy_score(labels_test, predictions))\n",
    "        precision.append(precision_score(labels_test, predictions))\n",
    "        recall.append(recall_score(labels_test, predictions))\n",
    "        if trial % 10 == 0:\n",
    "            if first:\n",
    "                sys.stdout.write('\\nProcessing')\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            first = False\n",
    "\n",
    "    print (\"done.\\n\")\n",
    "    print (\"precision: {}\".format(mean(precision)))\n",
    "    print (\"recall:    {}\".format(mean(recall)))\n",
    "    return mean(precision), mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.4629273698523699\n",
      "recall:    0.4049765873015873\n",
      "DecisionTreeClassifier(random_state=42)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.42463833388833394\n",
      "recall:    0.3971323454323454\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1e-08, multi_class='ovr', random_state=42,\n",
      "                                    solver='liblinear', tol=0.001))])\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.39017214835817776\n",
      "recall:    0.5921176406926406\n",
      "KMeans(n_clusters=2, tol=0.001)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.34572295041210005\n",
      "recall:    0.4400880952380953\n",
      "RandomForestClassifier(max_depth=5, max_features='sqrt', n_estimators=10,\n",
      "                       random_state=42)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.5135265873015874\n",
      "recall:    0.26066414141414146\n",
      "GradientBoostingClassifier(random_state=42)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.43576684704184704\n",
      "recall:    0.33185082972582974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43576684704184704, 0.33185082972582974)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf(g_clf, features, labels)\n",
    "evaluate_clf(d_clf, features, labels)\n",
    "evaluate_clf(l_clf, features, labels)\n",
    "evaluate_clf(k_clf, features, labels)\n",
    "evaluate_clf(rf_clf, features, labels)\n",
    "evaluate_clf(gb_clf, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two best models for our case seems to be the LogisticRegression and the DecisionTree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Tune your classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using our testing script. Check the tester.py script in the final project\n",
    "folder for details on the evaluation method, especially the test_classifier\n",
    "function. Because of the small size of the dataset, the script uses\n",
    "stratified shuffle split cross validation. For more info: \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the two best models from the evaluate function (DecisionTree and LogisticRegression), in order to tune the hyperparameters. \n",
    "We create a pipeline to run a GridSearch on the select K best as to find the best features selection number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('select_features', SelectKBest()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = np.arange(1, 20)\n",
    "my_feature_list = features_list \n",
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Set a pipeline with the features selected previously and classify them\n",
    "pipe_k = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "param_grid = [\n",
    "    {\n",
    "        'select_features__k': n_features\n",
    "    }\n",
    "]\n",
    "\n",
    "# We use the GridSearchCV tool in order to automatize the procedure and find the best number of features\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "k_lcf= GridSearchCV(pipe_k, param_grid=param_grid, scoring='f1', cv = 10)\n",
    "k_lcf.fit(features, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('select_features', SelectKBest(k=6)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_lcf.best_score_\n",
    "k_lcf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.7816913   0.06233576 16.95719491  2.20445373 26.5605672   6.27032312\n",
      "  7.00482086 12.56239963  7.79759949 10.37309462  0.06764556 25.10415132\n",
      "  9.53332413 26.46587154  0.13885137 11.74247165  3.34065915 12.09832639\n",
      "  2.27518447  5.76594457 16.27553035  3.43989738 16.78134655 20.61205177]\n",
      "6 best features: dict_keys(['bonus', 'exercised_stock_options', 'total_stock_value', 'salary', 'bonus_to_total', 'deferred_income'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new copies of feature list for grading\n",
    "my_feature_list = features_list\n",
    "\n",
    "# Get K-best features\n",
    "num_features = 6\n",
    "# Functio using SelectKBest\n",
    "def get_k_best(data_dict, features_list, k):\n",
    "    \"\"\" runs scikit-learn's SelectKBest feature selection\n",
    "        returns dict where keys=features, values=scores\n",
    "    \"\"\"\n",
    "    data = featureFormat(data_dict, features_list)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "\n",
    "    k_best = SelectKBest(k='all')\n",
    "    k_best.fit(features, labels)\n",
    "    scores = k_best.scores_\n",
    "    print(scores)\n",
    "    unsorted_pairs = zip(features_list[1:], scores)\n",
    "    sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "    k_best_features = dict(sorted_pairs[:k])\n",
    "    print (\"{0} best features: {1}\\n\".format(k, k_best_features.keys(), scores))\n",
    "    return k_best_features\n",
    "\n",
    "\n",
    "best_features = get_k_best(my_dataset, my_feature_list, num_features)\n",
    "\n",
    "my_feature_list = [target_label] + list(set(best_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.23151365 19.49852458 34.10091227 23.67763405 16.20440327 25.35659192]\n",
      "6 best features: dict_keys(['bonus', 'exercised_stock_options', 'total_stock_value', 'salary', 'bonus_to_total', 'deferred_income'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_features = get_k_best(my_dataset, my_feature_list, num_features)\n",
    "my_feature_list = [target_label] + list(set(best_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_log = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = [\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "c_values = np.logspace(-4, 4, 50)\n",
    "class_weight=['balanced',None]\n",
    "multi_class=[\"ovr\"]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(classifier__solver=solvers,classifier__penalty=penalty,classifier__C=c_values,classifier__class_weight=class_weight,classifier__multi_class=multi_class)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, train_size=0.7,random_state=42)\n",
    "grid_search = GridSearchCV(estimator=pipe_log, param_grid=grid, n_jobs=-1, cv=cv,scoring = 'f1')\n",
    "grid_result = grid_search.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=0.0001, multi_class='ovr',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.0001,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__multi_class': 'ovr',\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rl=Pipeline(steps=[('std_slc', StandardScaler()),\n",
    "                ('logistic_Reg',\n",
    "                 LogisticRegression(C=0.0001,\n",
    "                                    class_weight=None, multi_class='ovr',penalty= 'l2',\n",
    "                                    solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('std_slc', StandardScaler()),\n",
      "                ('logistic_Reg',\n",
      "                 LogisticRegression(C=0.0001, multi_class='ovr',\n",
      "                                    solver='liblinear'))])\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.5472570707070707\n",
      "recall:    0.4316101454101454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5472570707070707, 0.4316101454101454)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf(clf_rl,features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_rl, open(\"../final_project/my_classifier.pkl\", \"wb\"))\n",
    "pickle.dump(my_dataset, open(\"../final_project/my_dataset.pkl\", \"wb\"))\n",
    "pickle.dump(my_feature_list, open(\"../final_project/my_feature_list.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('std_slc', StandardScaler()),\n",
      "                ('logistic_Reg',\n",
      "                 LogisticRegression(C=0.0001, multi_class='ovr',\n",
      "                                    solver='liblinear'))])\n",
      "\tAccuracy: 0.86450\tPrecision: 0.53169\tRecall: 0.43200\tF1: 0.47669\tF2: 0.44883\n",
      "\tTotal predictions: 14000\tTrue positives:  864\tFalse positives:  761\tFalse negatives: 1136\tTrue negatives: 11239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf_rl, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(n_splits=folds, random_state=42)\n",
    "    \n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv.split(features, labels):\n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf_rl.fit(features_train, labels_train)\n",
    "        predictions = clf_rl.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "                print (\"All predictions should take value 0 or 1.\")\n",
    "                print (\"Evaluating performance for processed predictions:\")\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print (clf_rl)\n",
    "        print (PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5))\n",
    "        print (RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives))\n",
    "        print (\"\")\n",
    "    except:\n",
    "        print (\"Got a divide by zero when trying out:\", clf_rl)\n",
    "        print (\"Precision or recall may be undefined due to a lack of true positive predicitons.\")\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf_rl, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"wb\") as clf_rl_outfile:\n",
    "        pickle.dump(clf_rl, clf_rl_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"wb\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"wb\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"rb\") as clf_rl_infile:\n",
    "        clf_rl = pickle.load(clf_rl_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"rb\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"rb\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf_rl, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf_rl, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf_rl, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified that the Decision tree is our best model so we would like to tune the hyperparameters in order to improve our results. We will analyze the best number of features to use on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('select_features', SelectKBest()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'select_features__k': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])}],\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = np.arange(1, 20)\n",
    "my_feature_list = features_list \n",
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Set a pipeline with the features selected previously and classify them\n",
    "pipe_k1 = Pipeline([\n",
    "    ('select_features', SelectKBest()),\n",
    "    ('classifier',DecisionTreeClassifier())])\n",
    "param_grid = [\n",
    "    {\n",
    "        'select_features__k': n_features\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# We use the GridSearchCV tool in order to automatize the procedure and find the best number of features\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "k_clf= GridSearchCV(pipe_k1, param_grid=param_grid, scoring='f1', cv = cv)\n",
    "k_clf.fit(features, labels)\n",
    "\n",
    "# We use the GridSearchCV tool in order to automatize the procedure and find the best number of features\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "k_lcf= GridSearchCV(pipe_k, param_grid=param_grid, scoring='f1', cv = 10)\n",
    "k_lcf.fit(features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4333111333111333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('select_features', SelectKBest(k=12)),\n",
       "                ('classifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_clf.best_score_\n",
    "k_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35.7816913   0.06233576 16.95719491  2.20445373 26.5605672   6.27032312\n",
      "  7.00482086 12.56239963  7.79759949 10.37309462  0.06764556 25.10415132\n",
      "  9.53332413 26.46587154  0.13885137 11.74247165  3.34065915 12.09832639\n",
      "  2.27518447  5.76594457 16.27553035  3.43989738 16.78134655 20.61205177]\n",
      "12 best features: dict_keys(['bonus', 'exercised_stock_options', 'total_stock_value', 'salary', 'bonus_to_total', 'deferred_income', 'bonus_to_salary', 'fraction_to_poi', 'long_term_incentive', 'shared_receipt_with_poi', 'from_poi_to_this_person', 'restricted_stock'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_features = get_k_best(my_dataset, my_feature_list, num_features)\n",
    "my_feature_list = [target_label] + list(set(best_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_parameters = { 'criterion': ['gini', 'entropy'],\n",
    "                   'max_depth': [None, 1, 2, 4, 5, 10, 15, 20],\n",
    "                   'min_samples_split': [2, 4, 6, 8, 10, 20, 30, 40],\n",
    "                   'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 10, 20, 30] }\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), param_grid = clf_parameters, cv = cv, scoring = 'f1')\n",
    "clf.fit(features,labels)\n",
    "\n",
    "clf.best_estimator_\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion= 'gini',\n",
    " max_depth = 10,\n",
    " min_samples_leaf = 1,\n",
    " min_samples_split = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10, min_samples_split=4)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.3730664143862673\n",
      "recall:    0.35953639971139967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3730664143862673, 0.35953639971139967)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf(clf,features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"../final_project/my_classifier.pkl\", \"wb\"))\n",
    "pickle.dump(my_dataset, open(\"../final_project/my_dataset.pkl\", \"wb\"))\n",
    "pickle.dump(my_feature_list, open(\"../final_project/my_feature_list.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10, min_samples_split=4)\n",
      "\tAccuracy: 0.84857\tPrecision: 0.46678\tRecall: 0.42150\tF1: 0.44298\tF2: 0.42984\n",
      "\tTotal predictions: 14000\tTrue positives:  843\tFalse positives:  963\tFalse negatives: 1157\tTrue negatives: 11037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(n_splits=folds, random_state=42)\n",
    "    \n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv.split(features, labels):\n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "                print (\"All predictions should take value 0 or 1.\")\n",
    "                print (\"Evaluating performance for processed predictions:\")\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print (clf)\n",
    "        print (PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5))\n",
    "        print (RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives))\n",
    "        print (\"\")\n",
    "    except:\n",
    "        print (\"Got a divide by zero when trying out:\", clf)\n",
    "        print (\"Precision or recall may be undefined due to a lack of true positive predicitons.\")\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"wb\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"wb\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"wb\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"rb\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"rb\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"rb\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results after parameter tunning we discovered that Logistic Regression had a \n",
    "better performance than Decision Tree. We were skeptical about the difference of results for the evaluate function of the logistic Regression and its tester. The Decision Tree model seems to be the more consistent between both. Considering the latter, we would rather select the Decision tree Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"../final_project/my_classifier.pkl\", \"wb\"))\n",
    "pickle.dump(my_dataset, open(\"../final_project/my_dataset.pkl\", \"wb\"))\n",
    "pickle.dump(my_feature_list, open(\"../final_project/my_feature_list.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Dump your classifier, dataset, and features_list so anyone can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your results. You do not need to change anything below, but make sure\n",
    "that the version of poi_id.py that you submit can be run on its own and\n",
    "generates the necessary .pkl files for validating your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
